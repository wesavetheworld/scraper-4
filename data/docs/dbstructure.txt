// ******************************* INFORMATION *******************************//

// ***************************************************************************//
//  
// ** dbstructure - This is just a brainstorming file and does not represent
// ** anything currently in production
// ** 
// ** @author	Joshua Heiland <thezenman@gmail.com>
// ** @date	 2011-07-12
//  	
// ***************************************************************************//

// ********************************** START **********************************//

app design 

- 2 nodes running mongodb(master/slave)
	The most amount of memory since mongo does memory mapping for speed
	Master node will hold MySql as well
- 1 node running the brain or main routing (client gearman) selecting/updating functions
	requires large amount of memory to keep track of keyword objects
- 1 node running the job queue (job server gearman)	
- X nodes handle scraping (worker gearman)
- #(maybe not) X nodes parse scraped content and return requested data(rankings,pr, etc) 
- 1 node (S3 or just a regular node) for saved searches


Database structure strategy

	Perfect scenario for scraping

		(1) fast selects
		(2) fast updates
	
			(1) Selecting 
				"Select all keywords where schedule = hourly" 
					returns: array of keywords
							 keyword = array(keyword, country, domain, last rank)
		
	        (2) Updating 
	
	Perfect scenario for loading user's dashboards  
	
	 	single user object from a single query with no joins
	         - "select row where user_id = user_id"
				returns: single object
				
		benefits
			- This object would contain all of the users data, so no complex queries needed based on current page
			- Codeigniter could cache the user object so whichever group the user navigates to, a new query wouldn't be needed - blazing fast page loads
						  
	
	
	
	Concepts:

		Divide query types by load
			- expensive
				Queries that will take up more time/cpu, but are more precise
			- cheap
				Queries that will be very fast but less precise therefor temporary while waiting for a scheduled expensive task
	
		New data table
			Every hour a temporary table is used to hold all of the scraped data for that hour. No updates required, only inserts
			Once all of the data is collected, all of the new data is transferred to the main rankings collection
			The temporary collection is emptied    
		
		
	   Rolling updates
	 		- hourly
				Once an hour each premium user's object gets updated with the latest rankings
			- daily
				once a day each free user's object gets updated with the latest rankings
				once a day every user's object gets updated with historical data (1 day, 7 day, 30 day change rankings)
		
		
		